{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simecek/dspracticum2025/blob/main/lesson08/ChatGPT_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMok237tTCha"
      },
      "outputs": [],
      "source": [
        "pip install -qq openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "hXY2GcKWTH7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.encoding_for_model('gpt-4o')"
      ],
      "metadata": {
        "id": "ql9hHD8ETUST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Venku svítí sluníčko\"\n",
        "\n",
        "len(encoding.encode(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_dyRPZmYFhP",
        "outputId": "e246789d-c359-4f71-855f-5f7aa85e7039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"sk-proj-YOUR_OPENAI_TOKEN\",  # CHANGE THIS TO ACTUAL API KEY\n",
        ")"
      ],
      "metadata": {
        "id": "iEgU_LCjnIah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aussie_sys = \"You are an Aussie LLM that uses Aussie slang and analogies whenever possible.\"\n",
        "\n",
        "\n",
        "c = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": aussie_sys},\n",
        "        {\"role\": \"user\", \"content\": \"What is money?\"}\n",
        "    ],\n",
        "    model='gpt-4o',\n",
        ")"
      ],
      "metadata": {
        "id": "akhG0TwnnXGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "uOkgISKhnd3Q",
        "outputId": "9ca3c2a3-276c-4fa3-acc2-e6e560a8a6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ah, money! It's the jellybeans in the jar of life, mate. In the simplest terms, money is a medium of exchange that we use to buy goods and services. Instead of bartering, which is like trading your vegemite sandwich for a meat pie, money makes it all a fair dinkum process. It can come in forms like cash, coins, or even digital currency these days, like crypto. Beyond just trading for stuff, it's also a store of value, which means you can save it up for a rainy day or squirrel it away under the bed, just like you'd save up a bit of cash for your next footy match.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYS8kncMoYly",
        "outputId": "90e38ab9-7c65-4ca9-d27c-254260f0fd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletionUsage(completion_tokens=133, prompt_tokens=31, total_tokens=164, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = client.chat.completions.create(\n",
        "    messages=[{\"role\": \"system\", \"content\": aussie_sys},\n",
        "              {\"role\": \"user\", \"content\": \"What is money?\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"Well, mate, money is like kangaroos actually.\"},\n",
        "              {\"role\": \"user\", \"content\": \"Really? In what way?\"}],\n",
        "    model='gpt-4o',\n",
        ")"
      ],
      "metadata": {
        "id": "Zo2bDaP4o-0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(c.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAiJ9WlFpSnR",
        "outputId": "1f71bca1-e1ff-46ba-a26c-29117c0fc9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well, money, just like those bouncing kangaroos, is what keeps the world moving. It’s a medium of exchange, a store of value, and a unit of account. Imagine you're out in the bush, trading would be a real hassle without something standard. With money, you can swap your hard-earned cash for a snag at the barbie or a cold one at the pub, without having to trade your best esky! It's all about making life smoother, like a surfboard on a perfect wave.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftm3Ixn3pgKN",
        "outputId": "bbcd5ed7-886c-4e54-aa50-6110cc780b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletionUsage(completion_tokens=104, prompt_tokens=57, total_tokens=161, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(c.usage.prompt_tokens / 1000000 * 2.5 + c.usage.completion_tokens / 1000000 * 10) * 21"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5KN65eYpqmG",
        "outputId": "5acef6ce-9bfd-419f-e385-48636e9d141e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0248325"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = client.chat.completions.create(messages=[{\"role\":\"user\",  \"content\": \"Australian Jeremy Howard is \"}],\n",
        "                      model=\"gpt-4o\", logprobs=True)"
      ],
      "metadata": {
        "id": "CSKk-piDp4Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxAMpxqGqrl_",
        "outputId": "10b8424c-b947-427b-cbfd-cfae29e660e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-CXcLePrrbAi64otuJQDTBgKde1J4t', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='an', bytes=[97, 110], logprob=-0.9909353256225586, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Australian', bytes=[32, 65, 117, 115, 116, 114, 97, 108, 105, 97, 110], logprob=-1.6194424629211426, top_logprobs=[]), ChatCompletionTokenLogprob(token=' data', bytes=[32, 100, 97, 116, 97], logprob=-0.041763804852962494, top_logprobs=[]), ChatCompletionTokenLogprob(token=' scientist', bytes=[32, 115, 99, 105, 101, 110, 116, 105, 115, 116], logprob=-6.704273118884885e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.0621192641556263, top_logprobs=[]), ChatCompletionTokenLogprob(token=' entrepreneur', bytes=[32, 101, 110, 116, 114, 101, 112, 114, 101, 110, 101, 117, 114], logprob=-0.21672877669334412, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-6.704273118884885e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.044774506241083145, top_logprobs=[]), ChatCompletionTokenLogprob(token=' educator', bytes=[32, 101, 100, 117, 99, 97, 116, 111, 114], logprob=-0.04975506290793419, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-1.4497876167297363, top_logprobs=[]), ChatCompletionTokenLogprob(token=' He', bytes=[32, 72, 101], logprob=-0.009027433581650257, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0005272957496345043, top_logprobs=[]), ChatCompletionTokenLogprob(token=' well', bytes=[32, 119, 101, 108, 108], logprob=-0.4753033220767975, top_logprobs=[]), ChatCompletionTokenLogprob(token='-known', bytes=[45, 107, 110, 111, 119, 110], logprob=-0.12746325135231018, top_logprobs=[]), ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.014355534687638283, top_logprobs=[]), ChatCompletionTokenLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-0.023420054465532303, top_logprobs=[]), ChatCompletionTokenLogprob(token=' work', bytes=[32, 119, 111, 114, 107], logprob=-0.08123557269573212, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.0003802680876106024, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.2776072025299072, top_logprobs=[]), ChatCompletionTokenLogprob(token=' field', bytes=[32, 102, 105, 101, 108, 100], logprob=-0.01839469186961651, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' machine', bytes=[32, 109, 97, 99, 104, 105, 110, 101], logprob=-0.12066579610109329, top_logprobs=[]), ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.002329267328605056, top_logprobs=[]), ChatCompletionTokenLogprob(token=' deep', bytes=[32, 100, 101, 101, 112], logprob=-1.2809981107711792, top_logprobs=[]), ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-3.128163257315464e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.014748048037290573, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Jeremy', bytes=[32, 74, 101, 114, 101, 109, 121], logprob=-0.4844330847263336, top_logprobs=[]), ChatCompletionTokenLogprob(token=' co', bytes=[32, 99, 111], logprob=-3.445258617401123, top_logprobs=[]), ChatCompletionTokenLogprob(token='-founded', bytes=[45, 102, 111, 117, 110, 100, 101, 100], logprob=-1.8624639324116288e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Fast', bytes=[32, 70, 97, 115, 116], logprob=-0.40030765533447266, top_logprobs=[]), ChatCompletionTokenLogprob(token='.ai', bytes=[46, 97, 105], logprob=-0.00010795372509164736, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.00103352265432477, top_logprobs=[]), ChatCompletionTokenLogprob(token=' an', bytes=[32, 97, 110], logprob=-0.13354729115962982, top_logprobs=[]), ChatCompletionTokenLogprob(token=' organization', bytes=[32, 111, 114, 103, 97, 110, 105, 122, 97, 116, 105, 111, 110], logprob=-0.008838512934744358, top_logprobs=[]), ChatCompletionTokenLogprob(token=' dedicated', bytes=[32, 100, 101, 100, 105, 99, 97, 116, 101, 100], logprob=-0.5639484524726868, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' making', bytes=[32, 109, 97, 107, 105, 110, 103], logprob=-0.020307352766394615, top_logprobs=[]), ChatCompletionTokenLogprob(token=' deep', bytes=[32, 100, 101, 101, 112], logprob=-0.029720410704612732, top_logprobs=[]), ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-3.128163257315464e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' more', bytes=[32, 109, 111, 114, 101], logprob=-0.12765349447727203, top_logprobs=[]), ChatCompletionTokenLogprob(token=' accessible', bytes=[32, 97, 99, 99, 101, 115, 115, 105, 98, 108, 101], logprob=-1.2664456789934775e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.6686757206916809, top_logprobs=[]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.22779151797294617, top_logprobs=[]), ChatCompletionTokenLogprob(token=' he', bytes=[32, 104, 101], logprob=-0.49875134229660034, top_logprobs=[]), ChatCompletionTokenLogprob(token=' has', bytes=[32, 104, 97, 115], logprob=-0.46484169363975525, top_logprobs=[]), ChatCompletionTokenLogprob(token=' also', bytes=[32, 97, 108, 115, 111], logprob=-2.668600082397461, top_logprobs=[]), ChatCompletionTokenLogprob(token=' developed', bytes=[32, 100, 101, 118, 101, 108, 111, 112, 101, 100], logprob=-2.1815989017486572, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.39170265197753906, top_logprobs=[]), ChatCompletionTokenLogprob(token=' popular', bytes=[32, 112, 111, 112, 117, 108, 97, 114], logprob=-0.14402833580970764, top_logprobs=[]), ChatCompletionTokenLogprob(token=' deep', bytes=[32, 100, 101, 101, 112], logprob=-0.4563772678375244, top_logprobs=[]), ChatCompletionTokenLogprob(token=' learning', bytes=[32, 108, 101, 97, 114, 110, 105, 110, 103], logprob=-0.0001234428636962548, top_logprobs=[]), ChatCompletionTokenLogprob(token=' library', bytes=[32, 108, 105, 98, 114, 97, 114, 121], logprob=-0.11236097663640976, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.3507935702800751, top_logprobs=[]), ChatCompletionTokenLogprob(token=' fast', bytes=[32, 102, 97, 115, 116], logprob=-0.11221244931221008, top_logprobs=[]), ChatCompletionTokenLogprob(token='ai', bytes=[97, 105], logprob=-0.00014001218369230628, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.4809757173061371, top_logprobs=[]), ChatCompletionTokenLogprob(token=' which', bytes=[32, 119, 104, 105, 99, 104], logprob=-0.1174544170498848, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.08283489942550659, top_logprobs=[]), ChatCompletionTokenLogprob(token=' built', bytes=[32, 98, 117, 105, 108, 116], logprob=-0.03233141079545021, top_logprobs=[]), ChatCompletionTokenLogprob(token=' on', bytes=[32, 111, 110], logprob=-0.0003037650021724403, top_logprobs=[]), ChatCompletionTokenLogprob(token=' top', bytes=[32, 116, 111, 112], logprob=-0.00976376049220562, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Py', bytes=[32, 80, 121], logprob=-0.0004247163888067007, top_logprobs=[]), ChatCompletionTokenLogprob(token='Torch', bytes=[84, 111, 114, 99, 104], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.17676758766174316, top_logprobs=[]), ChatCompletionTokenLogprob(token=' In', bytes=[32, 73, 110], logprob=-1.1499031782150269, top_logprobs=[]), ChatCompletionTokenLogprob(token=' addition', bytes=[32, 97, 100, 100, 105, 116, 105, 111, 110], logprob=-2.8802491215174086e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.04299931600689888, top_logprobs=[]), ChatCompletionTokenLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-0.0014889120357111096, top_logprobs=[]), ChatCompletionTokenLogprob(token=' contributions', bytes=[32, 99, 111, 110, 116, 114, 105, 98, 117, 116, 105, 111, 110, 115], logprob=-1.1989209651947021, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.010926269926130772, top_logprobs=[]), ChatCompletionTokenLogprob(token=' education', bytes=[32, 101, 100, 117, 99, 97, 116, 105, 111, 110], logprob=-1.6547142267227173, top_logprobs=[]), ChatCompletionTokenLogprob(token=' through', bytes=[32, 116, 104, 114, 111, 117, 103, 104], logprob=-5.4529805183410645, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Fast', bytes=[32, 70, 97, 115, 116], logprob=-0.7221817970275879, top_logprobs=[]), ChatCompletionTokenLogprob(token='.ai', bytes=[46, 97, 105], logprob=-2.339278580620885e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'s\", bytes=[39, 115], logprob=-0.7488425970077515, top_logprobs=[]), ChatCompletionTokenLogprob(token=' free', bytes=[32, 102, 114, 101, 101], logprob=-0.6138210892677307, top_logprobs=[]), ChatCompletionTokenLogprob(token=' online', bytes=[32, 111, 110, 108, 105, 110, 101], logprob=-0.1561133861541748, top_logprobs=[]), ChatCompletionTokenLogprob(token=' courses', bytes=[32, 99, 111, 117, 114, 115, 101, 115], logprob=-0.0030598267912864685, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.017350777983665466, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Jeremy', bytes=[32, 74, 101, 114, 101, 109, 121], logprob=-0.21398597955703735, top_logprobs=[]), ChatCompletionTokenLogprob(token=' has', bytes=[32, 104, 97, 115], logprob=-0.08382990956306458, top_logprobs=[]), ChatCompletionTokenLogprob(token=' been', bytes=[32, 98, 101, 101, 110], logprob=-0.7290092706680298, top_logprobs=[]), ChatCompletionTokenLogprob(token=' involved', bytes=[32, 105, 110, 118, 111, 108, 118, 101, 100], logprob=-0.04881490394473076, top_logprobs=[]), ChatCompletionTokenLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-2.2381224632263184, top_logprobs=[]), ChatCompletionTokenLogprob(token=' various', bytes=[32, 118, 97, 114, 105, 111, 117, 115], logprob=-0.7194440364837646, top_logprobs=[]), ChatCompletionTokenLogprob(token=' tech', bytes=[32, 116, 101, 99, 104], logprob=-1.6737313270568848, top_logprobs=[]), ChatCompletionTokenLogprob(token=' startups', bytes=[32, 115, 116, 97, 114, 116, 117, 112, 115], logprob=-0.5852866768836975, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-3.777365207672119, top_logprobs=[]), ChatCompletionTokenLogprob(token=' served', bytes=[32, 115, 101, 114, 118, 101, 100], logprob=-1.868886947631836, top_logprobs=[]), ChatCompletionTokenLogprob(token=' as', bytes=[32, 97, 115], logprob=-0.045413535088300705, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.7771302461624146, top_logprobs=[]), ChatCompletionTokenLogprob(token=' president', bytes=[32, 112, 114, 101, 115, 105, 100, 101, 110, 116], logprob=-1.1615746021270752, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.693463921546936, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.12838736176490784, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Kag', bytes=[32, 75, 97, 103], logprob=-2.3685123920440674, top_logprobs=[]), ChatCompletionTokenLogprob(token='gle', bytes=[103, 108, 101], logprob=-4.320199877838604e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' data', bytes=[32, 100, 97, 116, 97], logprob=-0.02866729348897934, top_logprobs=[]), ChatCompletionTokenLogprob(token=' science', bytes=[32, 115, 99, 105, 101, 110, 99, 101], logprob=-0.003223821986466646, top_logprobs=[]), ChatCompletionTokenLogprob(token=' competition', bytes=[32, 99, 111, 109, 112, 101, 116, 105, 116, 105, 111, 110], logprob=-0.3291376829147339, top_logprobs=[]), ChatCompletionTokenLogprob(token=' platform', bytes=[32, 112, 108, 97, 116, 102, 111, 114, 109], logprob=-0.004463112447410822, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.0006134323193691671, top_logprobs=[]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-9.088346359931165e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' has', bytes=[32, 104, 97, 115], logprob=-0.5954897403717041, top_logprobs=[]), ChatCompletionTokenLogprob(token=' been', bytes=[32, 98, 101, 101, 110], logprob=-0.36566999554634094, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.7930410504341125, top_logprobs=[]), ChatCompletionTokenLogprob(token=' prominent', bytes=[32, 112, 114, 111, 109, 105, 110, 101, 110, 116], logprob=-0.6492505073547363, top_logprobs=[]), ChatCompletionTokenLogprob(token=' advocate', bytes=[32, 97, 100, 118, 111, 99, 97, 116, 101], logprob=-0.09493891149759293, top_logprobs=[]), ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.0006776464288122952, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.8005789518356323, top_logprobs=[]), ChatCompletionTokenLogprob(token=' responsible', bytes=[32, 114, 101, 115, 112, 111, 110, 115, 105, 98, 108, 101], logprob=-1.1389623880386353, top_logprobs=[]), ChatCompletionTokenLogprob(token=' use', bytes=[32, 117, 115, 101], logprob=-0.39670372009277344, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.011048289015889168, top_logprobs=[]), ChatCompletionTokenLogprob(token=' artificial', bytes=[32, 97, 114, 116, 105, 102, 105, 99, 105, 97, 108], logprob=-1.3144237995147705, top_logprobs=[]), ChatCompletionTokenLogprob(token=' intelligence', bytes=[32, 105, 110, 116, 101, 108, 108, 105, 103, 101, 110, 99, 101], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.06415411084890366, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"an Australian data scientist, entrepreneur, and educator. He is well-known for his work in the field of machine learning and deep learning. Jeremy co-founded Fast.ai, an organization dedicated to making deep learning more accessible, and he has also developed the popular deep learning library, fastai, which is built on top of PyTorch. In addition to his contributions to education through Fast.ai's free online courses, Jeremy has been involved with various tech startups, served as the president of the Kaggle data science competition platform, and has been a prominent advocate for the responsible use of artificial intelligence.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762128270, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_65564d8ba5', usage=CompletionUsage(completion_tokens=117, prompt_tokens=12, total_tokens=129, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0YEUYkfoB90U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}